{"config":{"lang":["fr"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Avant - propos","text":""},{"location":"#avant-propos","title":"Avant - propos","text":"<p>Pour acqu\u00e9rir un sens de la pratique, et s\u2019ouvrir \u00e0 l\u2019environnement professionnel, nous sommes amen\u00e9s \u00e0 r\u00e9diger une note de synth\u00e8se de mon traitement du Spam et Ozone Datasets incluant la d\u00e9marche, les principaux r\u00e9sultats et les conclusions.</p> <p>Dans ce cadre-l\u00e0, vient ce rapport auquel je vais synth\u00e9tiser le travail fait pendant mon traitement de Spam et Ozone Datasets.</p>"},{"location":"ozone%20dataset/","title":"Ozone dataset","text":""},{"location":"ozone%20dataset/#introduction","title":"Introduction","text":"<p>Le jeu de donn\u00e9es contient 1464 observations (journali\u00e8res, du 01/04/1995 au 30/09/2002, \u00e0 Rennes).</p>"},{"location":"ozone%20dataset/#preparation-des-donnees","title":"Pr\u00e9paration des donn\u00e9es","text":"<p><pre><code># Importer les biblioth\u00e8ques\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow import keras\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dropout\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.metrics import mean_squared_error\n</code></pre> Lors de l\u2019importation des donn\u00e9es, j\u2019ai remplac\u00e9 la colonne index par la colonne des dates. <pre><code># Importer le datasets + remplacer la colonne des indexes par celle des dates\nozone = pd.read_csv(\"ozone_complet.csv\", sep=\";\", index_col='Unnamed: 0')\n</code></pre> <pre><code># Lire les 5 premi\u00e8re lignes\nozone.head()\n</code></pre></p>"},{"location":"ozone%20dataset/#etude-exploratoire-des-donnees","title":"\u00c9tude exploratoire des donn\u00e9es","text":"<p><pre><code># Afficher quelques informations du dataset\nozone.info()\n</code></pre> <pre><code># Afficher quelques statistiques du dataset\nozone.describe()\n</code></pre> <pre><code># Analyse les distributions des donn\u00e9es\nozone.hist(bins=50, figsize=(20,15))\nplt.show()\n</code></pre></p> Output <p></p> <pre><code># Analyse des corr\u00e9lations\nmatriceCorr = ozone.corr().round(1)\nsns.heatmap(data=matriceCorr, annot = True)\n</code></pre> Output <p></p> <p><pre><code># Afficher le nombre des valeurs manquantes dans chaque colonne\nozone.isnull().sum()\n</code></pre> J\u2019ai ensuite remarqu\u00e9 qu\u2019il y avait des valeurs manquantes dans l\u2019ensemble de donn\u00e9es. Pour r\u00e9soudre ce probl\u00e8me, j\u2019ai remplac\u00e9 ces valeurs par la moyenne en utilisant \u00ab SimpleImputer \u00bb. <pre><code># Remplir les valeurs manquentes par la mayenne\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy=\"median\")\n</code></pre> <pre><code># Lancer l'entrainement de Imputer\nimputer.fit(ozone)\n</code></pre> <pre><code># Appliquer le mod\u00e8le Imputer sur le dataset ozone (la sortie est de type array)\nozone_complet = imputer.transform(ozone)\n</code></pre> <pre><code># Transformer le dataset (sortie de Imputer de type array) en data frame\nozone_complet = pd.DataFrame(ozone_complet, columns=ozone.columns)\n</code></pre> <pre><code># V\u00e9rifier qu'il n'ya plus de valeurs manquantes\nozone_complet.isnull().sum()\n</code></pre></p>"},{"location":"ozone%20dataset/#implementation-dun-modele-de-reseau-de-neurones","title":"Impl\u00e9mentation d\u2019un mod\u00e8le de r\u00e9seau de neurones","text":"<p><pre><code># Division de donn\u00e9es en donn\u00e9es d'entrainement, du test et de validation\nozone_complet = ozone_complet.sample(frac=1, axis=0)\ndata_train_valid = ozone_complet.sample(frac=0.85, axis=0)\ndata_test = ozone_complet.drop(data_train_valid.index)\ndata_train = data_train_valid.sample(frac=0.8, axis=0)\ndata_valid = data_train_valid.drop(data_train.index)\nx_train = data_train.drop('maxO3', axis=1)\ny_train = data_train['maxO3']\nprint('Dimensions de X train :', x_train.shape)\nprint('Dimensions de Y train :', y_train.shape)\nx_valid = data_valid.drop('maxO3', axis=1)\ny_valid = data_valid['maxO3']\nprint('Dimensions de X valid :', x_valid.shape)\nprint('Dimensions de Y valid :', y_valid.shape)\nx_test = data_test.drop('maxO3', axis=1)\ny_test = data_test['maxO3']\nprint('Dimensions de X test :', x_test.shape)\nprint('Dimensions de Y test :', y_test.shape)\n</code></pre> <pre><code># Normalisation des donn\u00e9es\nmin_x_train = x_train.min()\nmax_x_train = x_train.max()\nprint(\"Min de x_train :\", min_x_train)\nprint(\"Max de x_train :\", max_x_train)\nx_train_norm = (x_train-min_x_train)/(max_x_train-min_x_train)\nx_test_norm = (x_test-min_x_train)/(max_x_train-min_x_train)\nx_val_norm = (x_valid-min_x_train)/(max_x_train-min_x_train)\n</code></pre> La structure du perceptron se compose d\u2019une couche d\u2019entr\u00e9e avec 22 neurones correspondant \u00e0 chacune des 22 features, de deux couches cach\u00e9es avec 5 neurones par chacune et d\u2019une couche de sortie avec un seul neurone qui donnera la valeur pr\u00e9dite de \u00ab maxO3 \u00bb. La fonction ReLu a \u00e9t\u00e9 choisie comme fonction d\u2019activation pour chacune des trois couches, mean square error comme loss function, et l\u2019algorithme Adam optimizer pour son adaptative learning rate and momentum.</p> <p><pre><code>## Impl\u00e9mentation de mod\u00e8le DNN\nmodel = Sequential()\nmodel.add(Dense(22, input_dim=np.shape(x_train)[1], activation = 'relu'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(5, activation = 'relu'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(5, activation = 'relu'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(1, activation = 'relu'))\nmodel.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics=['mean_squared_error'])\nmodel.summary()\n</code></pre> <pre><code>callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=100)\nhist = model.fit(x_train_norm, y_train, epochs = 1000, batch_size = 9999, callbacks = callback)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\npred_train= model.predict(x_train_norm)\nprint(np.sqrt(mean_squared_error(y_train,pred_train)))\npred= model.predict(x_test_norm)\nprint(np.sqrt(mean_squared_error(y_test,pred)))\n</code></pre></p>"},{"location":"ozone%20dataset/#implementation-dune-regression-lineaire","title":"Impl\u00e9mentation d\u2019une R\u00e9gression Lin\u00e9aire","text":"<p>J\u2019ai \u00e9galement mis en \u0153uvre une r\u00e9gression lin\u00e9aire et j\u2019ai obtenu un score de 0,625 pour les donn\u00e9es de test et un score de 0,646 pour les donn\u00e9es de validation. <pre><code>from sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(x_train_norm, y_train)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\nscore_test_lin_reg = lin_reg.score(x_test_norm, y_test)\nprint(\"Test Accuracy Score\", score_test_lin_reg)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es de validation\nscore_valid_lin_reg = lin_reg.score(x_val_norm, y_valid)\nprint(\"Test Accuracy Score\", score_valid_lin_reg)\n</code></pre></p>"},{"location":"ozone%20dataset/#implementation-dun-svr","title":"Impl\u00e9mentation d\u2019un SVR","text":"<p>Un SVR a \u00e9galement \u00e9t\u00e9 mis en place et a donn\u00e9 un score de 0,489 pour les donn\u00e9es de test et un score de 0,519 pour les donn\u00e9es de validation. <pre><code>from sklearn.svm import SVR\nsvr = SVR()\nsvr.fit(x_train_norm, y_train)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\nscore_test_svr = svr.score(x_test_norm, y_test)\nprint(\"Test Accuracy Score\", score_test_svr)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es de validation\nscore_valid_svr = svr.score(x_val_norm, y_valid)\nprint(\"Test Accuracy Score\", score_valid_svr)\n</code></pre></p>"},{"location":"ozone%20dataset/#conclusion","title":"Conclusion","text":"<p>Pour conclure, voici un tableau qui r\u00e9sume les diff\u00e9rents scores de tous les mod\u00e8les que j\u2019ai mis en place :</p> Mod\u00e8le Score (test dataset) Score (validation dataset) R\u00e9seau de neurones (DNN) mean square error : 36.827398008235775 R\u00e9gression Lin\u00e9aire 0.6250066102296177 0.6463044934834267 SVM (SVR) 0.4895962389393179 0.5192747605192083"},{"location":"pr%C3%A9sentation%20de%20l%27%C3%A9nonc%C3%A9/","title":"Pr\u00e9sentation de l'\u00e9nonc\u00e9","text":""},{"location":"pr%C3%A9sentation%20de%20l%27%C3%A9nonc%C3%A9/#objectifs","title":"Objectifs","text":"<p>Proposer une mod\u00e9lisation pour les deux cas suivants : </p> <ol> <li> <p>Pr\u00e9voir le label d\u2019un mail (spam) \u00e0 partir de caract\u00e9ristiques du type \u00ab bags of words \u00bb (jeu de donn\u00e9es spam). </p> </li> <li> <p>Pr\u00e9voir la concentration en ozone (max03) \u00e0 partir des conditions m\u00e9t\u00e9orologiques et de la concentration d\u2019ozone de la veille (jeu de donn\u00e9es ozone_complet - attention il contient quelques donn\u00e9es manquantes).</p> </li> </ol>"},{"location":"pr%C3%A9sentation%20de%20l%27%C3%A9nonc%C3%A9/#attendus-techniques","title":"Attendus techniques","text":"<ul> <li> <p>Tester diff\u00e9rentes architectures de r\u00e9seaux de neurones sur les jeux de donn\u00e9es.</p> </li> <li> <p>Comparer les r\u00e9sultats obtenus avec les m\u00e9thodes \u00ab de base \u00bb (r\u00e9gression lin\u00e9aire dans le cadre de la r\u00e9gression, r\u00e9gression logistique dans le cadre de la classification supervis\u00e9e) et au moins une autre m\u00e9thode de machine learning (ex : random forest, gradient boosting, SVM-SVR).</p> </li> <li> <p>Adopter un protocole adapt\u00e9 aux jeux de donn\u00e9es (apprentissage-test, validation crois\u00e9e. . . / crit\u00e8re(s) d\u2019erreur).</p> </li> </ul>"},{"location":"pr%C3%A9sentation%20de%20l%27%C3%A9nonc%C3%A9/#consignes-generales","title":"Consignes g\u00e9n\u00e9rales","text":"<ul> <li> <p>Travail individuel.</p> </li> <li> <p>Date de rendu : mardi 31 janvier 2023.</p> </li> <li> <p>Rendus :</p> <ul> <li> <p>Une note de synth\u00e8se r\u00e9dig\u00e9e (environ 4 \u00e0 6 pages), incluant la d\u00e9marche, les principaux r\u00e9sultats et les conclusions (attention les notebooks ne seront pas accept\u00e9s pour cette partie).</p> </li> <li> <p>Le code et/ou le notebook associ\u00e9.</p> </li> </ul> </li> <li> <p>Point d\u2019attention : la r\u00e9daction a un poids majeur, un notebook seul ne suffira pas pour valider. . .</p> </li> </ul>"},{"location":"remerciement/","title":"Remerciement","text":""},{"location":"remerciement/#remerciements","title":"Remerciements","text":"<p>Je tiens \u00e0 t\u00e9moigner ma gratitude et ma reconnaissance \u00e0 toutes les personnes qui ont contribu\u00e9 \u00e0 la r\u00e9alisation de ce rapport et plus particuli\u00e8rement je remercie M. Lefieu mon professeur au sein de l\u2019Ecole Centrale Casablanca, pour le temps qu\u2019il m\u2019a accord\u00e9 pour r\u00e9pondre \u00e0 mes questions durant le cours et les TPs. Je le remercie aussi pour sa patience, son grand professionnalisme ainsi que sa g\u00e9n\u00e9rosit\u00e9.</p>"},{"location":"spam%20dataset/","title":"Spam dataset","text":""},{"location":"spam%20dataset/#introduction","title":"Introduction","text":"<p>L\u2019objectif de ce projet \u00e9tait d\u2019entra\u00eener un r\u00e9seau neuronal \u00e0 classer les courriels comme \u00ab spam \u00bb ou \u00ab non spam \u00bb. Ceci a \u00e9t\u00e9 fait sur le jeu de donn\u00e9es Spambase fourni par le r\u00e9f\u00e9rentiel d\u2019apprentissage automatique de l\u2019UCI, qui contient 57 features repr\u00e9sentant la fr\u00e9quence des mots dans 4601 emails.</p> <p>Pour notre label (Spam) ; \u00ab spam \u00bb a \u00e9t\u00e9 cod\u00e9 comme 1 pour la classe positive et \u00ab non spam \u00bb a \u00e9t\u00e9 a \u00e9t\u00e9 cod\u00e9 comme 0 pour la classe n\u00e9gative.</p>"},{"location":"spam%20dataset/#preparation-des-donnees","title":"Pr\u00e9paration des donn\u00e9es","text":"<p><pre><code># Importer les biblioth\u00e8ques\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow import keras\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dropout\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.layers import Dense\n</code></pre> <pre><code># Importer le datasets \nspam = pd.read_csv(\"spam.csv\")\n</code></pre> <pre><code># Lire les 5 premi\u00e8re lignes\nspam.head(5)\n</code></pre></p>"},{"location":"spam%20dataset/#etude-exploratoire-des-donnees","title":"\u00c9tude exploratoire des donn\u00e9es","text":"<p><pre><code># Afficher quelques informations du dataset\nspam.info()\n</code></pre> D\u2019apr\u00e8s le r\u00e9sultat de la m\u00e9thode \u00ab info() \u00bb, il appara\u00eet que tous les features sont de type float ce qui facilitera notre \u00e9tude ult\u00e9rieure (pas besoin de faire une feature engineering). <pre><code># Afficher quelques statistiques du dataset\nspam.describe()\n</code></pre> J\u2019ai \u00e9galement fait une analyse des distributions des donn\u00e9es pour avoir une id\u00e9e sur les lois suivies par les diff\u00e9rents features, ainsi veuillez trouver ci-dessous le r\u00e9sultat obtenu et qui montre que la plupart des features ne suivent pas une distribution gaussienne. <pre><code># Afficher quelques statistiques du dataset\nspam.describe()\n</code></pre></p> Output <p></p> <pre><code># Analyse des corr\u00e9lations\nmatriceCorr = spam.corr().round(1)\nsns.heatmap(data=matriceCorr, annot = True)\n</code></pre> Output <p></p>"},{"location":"spam%20dataset/#implementation-dun-modele-de-reseau-de-neurones","title":"Impl\u00e9mentation d\u2019un mod\u00e8le de r\u00e9seau de neurones","text":"<p><pre><code># Division de donn\u00e9es en donn\u00e9es d'entrainement, du test et de validation\nspam = spam.sample(frac=1, axis=0)\ndata_train_valid = spam.sample(frac=0.85, axis=0)\ndata_test = spam.drop(data_train_valid.index)\ndata_train = data_train_valid.sample(frac=0.8, axis=0)\ndata_valid = data_train_valid.drop(data_train.index)\nx_train = data_train.drop('spam', axis=1)\ny_train = data_train['spam']\nprint('Dimensions de X train :', x_train.shape)\nprint('Dimensions de Y train :', y_train.shape)\nx_valid = data_valid.drop('spam', axis=1)\ny_valid = data_valid['spam']\nprint('Dimensions de X valid :', x_valid.shape)\nprint('Dimensions de Y valid :', y_valid.shape)\nx_test = data_test.drop('spam', axis=1)\ny_test = data_test['spam']\nprint('Dimensions de X test :', x_test.shape)\nprint('Dimensions de Y test :', y_test.shape)\n</code></pre> <pre><code># Normalisation des donn\u00e9es\nmin_x_train = x_train.min()\nmax_x_train = x_train.max()\nprint(\"Min de x_train :\", min_x_train)\nprint(\"Max de x_train :\", max_x_train)\nx_train_norm = (x_train-min_x_train)/(max_x_train-min_x_train)\nx_test_norm = (x_test-min_x_train)/(max_x_train-min_x_train)\nx_val_norm = (x_valid-min_x_train)/(max_x_train-min_x_train)\n</code></pre> La structure du perceptron se compose d\u2019une couche d\u2019entr\u00e9e avec 57 neurones correspondant \u00e0 chacune des 57 features, d\u2019une couche cach\u00e9e avec 12 neurones et d\u2019une couche de sortie avec 2 neurones : le premier peut \u00eatre interpr\u00e9t\u00e9 comme la probabilit\u00e9 qu\u2019un email soit \u00ab non-spam \u00bb et le second comme la probabilit\u00e9 de \u201cspam\u201d. Le neurone de sortie ayant la probabilit\u00e9 la plus \u00e9lev\u00e9e d\u00e9termine la classification d\u2019un email.</p> <p>La fonction sigmo\u00efde a \u00e9t\u00e9 choisie comme fonction d\u2019activation pour chacune des trois couches, l\u2019entropie crois\u00e9e binaire comme loss function, et l\u2019algorithme Adam optimizer pour son adaptative learning rate and momentum.</p> <p></p> <p><pre><code>## Impl\u00e9mentation de mod\u00e8le DNN\nmodel = Sequential()\nmodel.add(Dense(57, input_dim=np.shape(x_train)[1], activation = 'sigmoid'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(12, activation = 'sigmoid'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\nmodel.summary()\n</code></pre> <pre><code>callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=1000)\nhist = model.fit(x_train_norm, y_train, epochs = 10100, batch_size = 99999, callbacks = callback)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\npreds = model.predict(x_test_norm)\npreds = [1 if x[0] &gt; 0.5 else 0 for x in preds]\nscore_test_dnn = accuracy_score(y_test, preds)\nprint(score_test_dnn)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es de validation\npreds = model.predict(x_val_norm)\npreds = [1 if x[0] &gt; 0.5 else 0 for x in preds]\nscore_valid_dnn = accuracy_score(y_valid, preds)\nprint(score_valid_dnn)\n</code></pre> <pre><code>figure = plt.gcf()\nfigure.set_size_inches((20, 10))\nplt.title('Analyse des erreurs')\nplt.xlabel('Epoch')\nplt.ylabel('Entropie crois\u00e9e')\nplt.plot(range(1, len(hist.history['loss']) + 1), hist.history['loss'])\nplt.legend(['Entropie crois\u00e9e train'])\nplt.show()\n</code></pre></p> Output <p></p> <pre><code>figure = plt.gcf()\nfigure.set_size_inches((20, 10))\nplt.title('Analyse des erreurs')\nplt.xlabel('Epoch')\nplt.ylabel('Pr\u00e9cision')\nplt.plot(range(1, len(hist.history['accuracy']) + 1), hist.history['accuracy'])\nplt.legend([\"Pr\u00e9cision d'apprentissage\"])\nplt.show()\n</code></pre> Output <p></p> <p>Ce mod\u00e8le de r\u00e9seau neuronal a donn\u00e9 un score de 0,924 pour les donn\u00e9es de test et un score de 0,937 pour les donn\u00e9es de validation, ce qui est tr\u00e8s satisfaisant.</p>"},{"location":"spam%20dataset/#implementation-dune-regression-logistique","title":"Impl\u00e9mentation d\u2019une R\u00e9gression Logistique","text":"<p><pre><code>from sklearn.linear_model import LogisticRegression\nlog_reg = LogisticRegression()\nlog_reg.fit(x_train_norm, y_train)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\nscore_test_log_reg = log_reg.score(x_test_norm, y_test)\nprint(\"Test Accuracy Score\", score_test_log_reg)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es de validation\nscore_valid_log_reg = log_reg.score(x_val_norm, y_valid)\nprint(\"Test Accuracy Score\", score_valid_log_reg)\n</code></pre> J\u2019ai \u00e9galement mis en \u0153uvre une r\u00e9gression logistique et j\u2019ai obtenu un score de 0,876 pour les donn\u00e9es de test et un score de 0,895 pour les donn\u00e9es de validation.</p>"},{"location":"spam%20dataset/#implementation-dun-svm","title":"Impl\u00e9mentation d\u2019un SVM","text":"<p><pre><code>from sklearn import svm\nsvm = svm.SVC()\nsvm.fit(x_train_norm, y_train)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\nscore_test_svc = svm.score(x_test_norm, y_test)\nprint(\"Test Accuracy Score\", score_test_svc)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es de validation\nscore_valid_svc = svm.score(x_val_norm, y_valid)\nprint(\"Test Accuracy Score\", score_valid_svc)\n</code></pre> Un SVC a \u00e9galement \u00e9t\u00e9 mis en place et a donn\u00e9 un score de 0,931 pour les donn\u00e9es de test et un score de 0,932 pour les donn\u00e9es de validation.</p>"},{"location":"spam%20dataset/#implementation-dun-random-forest","title":"Impl\u00e9mentation d\u2019un Random Forest","text":"<p><pre><code>from sklearn.ensemble import RandomForestClassifier\nrdf = RandomForestClassifier(max_depth=2, random_state=0)\nrdf.fit(x_train_norm, y_train)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\nscore_test_rdf = rdf.score(x_test_norm, y_test)\nprint(\"Test Accuracy Score\", score_test_rdf)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es de validation\nscore_valid_rdf = rdf.score(x_val_norm, y_valid)\nprint(\"Test Accuracy Score\", score_valid_rdf)\n</code></pre> Pour avoir une id\u00e9e de tous les mod\u00e8les de machine learning, j\u2019ai mis en \u0153uvre un Random Forest qui a donn\u00e9 un score de 0,884 pour les donn\u00e9es de test et un score de 0,904 pour les donn\u00e9es de validation.</p>"},{"location":"spam%20dataset/#conclusion","title":"Conclusion","text":"<p>Pour conclure, voici un tableau qui r\u00e9sume les diff\u00e9rents scores de tous les mod\u00e8les que j\u2019ai mis en place :</p> Mod\u00e8le Score (test dataset) Score (validation dataset) R\u00e9seau de neurones (DNN) 0.9246376811594202 0.9246376811594202 R\u00e9gression Logistique 0.8768115942028986 0.8951406649616368 SVM (SVC) 0.9318840579710145 0.9322250639386189 Random Forest 0.8840579710144928 0.9040920716112532"}]}